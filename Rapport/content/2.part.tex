\section{Les critères d'évaluation des projections}

Comme nous l’avons vu dans le chapitre précédent, la projection d'un jeu de données multidimensionnel passe par un processus de réduction de dimension. 
Or, celui-ci a un coût : il implique une perte de données qui va se répercuter lors de la représentation finale de celles-ci.\smallskip
La réduction induit une erreur : le stress qui a un impact sur l’approximation des distances au sein de la représentation.

Par définition, une bonne projection est une projection qui représente le plus fidèlement
possible la structure sous-jacente du jeu de données. Par conséquent, une
bonne configuration de projection est une configuration qui minimise le stress de la
projection. En d'autres termes: plus les distances entre le jeu de données et la projection seront proches, moins il y aura d’erreurs.
Ainsi, le but dans une projection est de minimiser le stress. \newline 
Mathématiquement parlant, le stress peut être défini comme la somme
quadratique des écarts de distances :  \[\epsilon_\psi = \sum_{i,j}^{n}[(d_m (x_i , x_j )- d_p (y_i ,y_j )]^{2} \] 


\subsection{Visualisation du stress}

Le stress va produire des artefacts lors de la projection de données. Ceux-ci vont
avoir un impact sur l’approximation et l'interprétation de la représentation graphique. Il y a
plusieurs façons de le quantifier :

Les mesures peuvent être locales, c'est-à-dire qu'elles sont visualisées en chaque point et aident à expliquer
la projection. C’est possible en utilisant un diagramme de Shepard \cite{kruskal1964multidimensional} \cite{HeulotThese}.
D'autres méthodes utilisent un \textit{jitter disc} autour de chaque point. Cela permet de visualiser le
stress, mais ne donne pas des informations sur les origines de celui-ci \cite{HeulotAnEvaluation}.

Il est également possible de le visualiser en utilisant un encodage colorimétrique, qui en
fonction d’une couleur et de son intensité indiquera les points les moins fiables de la
projection \cite{CheckViz}.
On peut aussi avoir recours à différents types d’interpolation de la couleur entre les points,
selon différents paramètres, ce qui forme une carte de précision \cite{schreck2010techniques}.
\smallskip

Une méthode pour mettre en avant les artefacts topologiques(faux voisinages et déchirures) a été mise en place par Lespinats et Aupetit \cite{CheckViz} : l’idée est de visualiser deux mesures de stress simultanément à l’aide d’une échelle de couleur 2D uniforme. 
Cela permet d’utiliser la projection malgré les erreurs de positionnement des différents points: cependant la mesure de qualité ne garantit pas qu’on puisse exploiter la projection(surtout pour les tâches de clustering visuel) .
\newline
Il y a également, des méthodes interactives avec différentes vues
possibles(stress) globaux, faux voisinages, déchirures …) selon les différents niveaux de
granularité (point seul ou groupes de points) \cite{abbas2019clustme} \cite{HeulotThese}. De plus, en fonction du type d’artefacts,
différentes mesures d’erreurs sont proposées : coloration interpolée ou edge bundling(arc
compact) pour, par exemple relier les points et faire le parallèle pour montrer les déchirures
sur la projection \cite{holten2006-EDGE1} \cite{holten2011-EDGE2} \cite{HeulotThese}. Les arcs sont aussi colorés de façon différente en fonction de l’intensité
des erreurs.\newline Ce système est interactif, car l’utilisateur peut choisir manuellement un groupe de point à
étudier afin de visualiser seulement les artefacts qui lui sont relatifs. Il y a aussi beaucoup de
vues statiques qui peuvent l’aider à filtrer.

\subsection{Les critères de mesure}

Pour évaluer la qualité d’une projection, plusieurs approches se basant sur différents ritères existant.
Ces critères peuvent être relatifs à la structure des données projetées avec le taux d’oublier de la projection (outlying), le taux de cluster et à leurs qualités(visual clustering, class consistency, cluster separator, class density), et à la forme de la projection (clumpy, skinny).
Nous allons les détailler au cours de ce chapitre.

\subsubsection{Clustering}
Le clustering sert à partitionner les données en groupe homogènes. En d’autres termes, cela consiste à évaluer si le jeu de données contient des groupes(ou clusters) ainsi que leur qualité (c'est-à-dire s’ ils sont séparés et facilement identifiables).
Pour cela, il existe plusieurs critères.

\begin{itemize}
\item
\textbf{Class consistency : }
\smallskip
Tout d'abord, il y a la mesure de la \textit{class consistency} \cite{bertini2011Class-Consistency}.
 Dans un jeu de données,chaque classe est composée d’un sous-ensemble de l'espace de données qui lui est assigné. Ainsi
chaque point est assigné à une classe. L’ensemble des classes du data-space est appelé
\textit{class structure}.
L'objectif est donc de vérifier si la séparation des classes est correcte en fonction des
dimensions étudiées, sachant qu’une bonne représentation visuelle d’une “Class structure”
doit être fidèle à cette même structure de classe. Pour déterminer cela, nous pouvons le
calculer selon la règle de la \textit{distance to centroid}: c’est-à-dire que
chaque point d’une classe doit être à une distance inférieure de son centroïde(i.e le centre de sa
classe) qu’à celui d’une autre classe.
Or c’est une des propriétés qui est très souvent perdue lors de la projection.
Par conséquent, si la \textit{class consistency} est bonne, les classes seront situées à des régions
visuellement séparées dans la projection graphique, les clusters seront donc plus
facilement discriminables et la projection potentiellement de meilleure qualité.

La class consistency est le plus souvent calculée de la façon suivante : 
[METTRE FORMULE]
Où Ck est la classe de p, centr(ck) est le centroid de cette même classe. m le nombre de classe disponible, et d(p, centr(ck) la fonction \textit{distance to centroid} )
\item
\textbf{Class density : }
\smallskip
 Pour justifier de la qualité du clustering d’une projection, nous pouvons également
mesurer la densité de classe (ou \textit{class density}).
Ce critère évalue la projection en fonction de ses propriété de séparation. Le but est
d'identifier les zones où il y a le moins de chevauchement entre les classes.


Pour calculer ce chevauchement entre classes, la méthode passe par l'utilisation d'une représentation continue du jeu de donnée : où les points
appartenants au même cluster forment une image différente. Cela revient à faire en sorte que pour chaque classe il y ai une image distincte avec
des densités continues et régulières calculée à partir du voisinage local de chaque point (ou pixel).

Le principe est donc de retenir les resultats avec le moins de chevauchement \cite{AndradaTatu2010visual}.
Ainsi, lors d’une projection, les points appartenant à un cluster forment une image, c'est -à
-dire que chaque classe forme une image.
L’algorithme se fait en fonction de la densité basée sur le voisinage : pour chaque pixel, la
distance de son voisin le plus proche de la même classe est enregistrée. Puis, la densité
locale est calculée dans une sphère de rayon de la distance maximum possible.
Le chevauchement global des classes est ensuite estimé en calculant la somme de la
différence de chaque paire de pixels à la valeur absolue. Puis la visualisation avec le
chevauchement le plus faible sera retenue.
\[CDM =  \sum_{k=1}^{m-1} \sum_{l=k+1}^{m} \sum_{i=1}^{P} \lVert P_{k}^{i} - P_{l}^{i} \rVert \]


\item
\textbf{Histogram density : }
\smallskip
Il y a aussi la mesure de l`\textit{histogram density} \cite{HeulotThese} \cite{AndradaTatu2009combining} qui est une mesure de l’entropie de la projection
(i.e l'information moyenne de différentes portions de la projection découpée en grille). La
projection est séparée en plusieurs barres (à l'image des histogrammes). Dans chacun de
ces bins on comptabilise le nombre de points et leur étiquette de classe. L’entropie de
chaque bin se calcule de cette façon. \[ H(p) = - \sum_{c} * \frac{P_c}{\sum_{c}*P_c} * \log_2 * \frac{P_c}{\sum_c * P_c} \]
Ainsi, si tous les points d’une barre sont de la même classe, alors l’entropie est égale à zéro. Par conséquent le clustering sera de bonne qualité.

\end{itemize}
\smallskip



\subsubsection{Outlying}

Le taux d’outliers est important à définir pour justifier de la qualité du clustering.
Un \textit{outlier} est une donnée aberrante. Pour déterminer si un point est un outlier, il y a plusieurs méthodes.

\textbf{Critères utilisant les graphes :}
\begin{itemize}
    \item Une des façons de raisonner en graphe et d'utiliser le concept de \textit{Minimum Spanning Tree}(MST) \cite{wilkinson2005graph-MST} , c'est-à-dire l'arbre le moins long que l'on peut créer à partir du nuage de points. 
    En prenant comme référentiel le MST, les outliers sont soit des points qui sont localisés aux extrémités de l’arbre ou en intérieur dans des régions relativement vides. 
    Ainsi, on peut les définir comme des nœuds de degrés 1, et dont la somme des poids des arêtes adjacentes est supérieure à ‘w’ selon la formule suivante  \[ \omega = q_{75} + 1.5 (q_{75} - q_{25} ) \].
    Avec q75 représentant le 75ème percentile de la longueur des arêtes du MST et la partie entre parenthèse représentant l'interval interquartile de la longueur des arêtes.
    Puis, nous pouvons calculer le taux d’outliers dans la projection (outlying) en divisant la longueur totale de tous les outliers par la longueur totale de l’arbre selon la formule suivante : \[c_{outlying} = length(T_{outliers} )/length(T) \] .
    \item Il y a également la méthode de l’\textit{isolation Forest}. Dans celle-ci, l’algorithme choisit une caractéristique du jeu donnée et une valeur \textit{split} comprise entre le maximum et le minimum des valeurs. Cette étape est effectuée pour toutes les observations. Par la suite la moyenne des tous les arbres est faite pour construire la forêt.L'apprentissage de l’algorithme consiste à comparer les observations avec la \textit{splitting value} dans un nœud. Ce nœud comprendra également deux sous-noeuds dans lesquels on fera aussi la même comparaison. Ainsi le nombre de \textit{splitting} est égal à la longueur du chemin. Toutes les comparaisons auront un score allant de 0 à 1. 0 signifiant "normalité", et 1 signifiant qu’il y a un grand nombre d’outlier\cite{togbe2020anomaly-IsolationForest}. Elle est implémentée en python avec scikit Learn.
\end{itemize} 

Puis, nous pouvons calculer le taux d’outliers dans la projection (outlying) en divisant la
longueur totale de tous les outliers par la longueur totale de l’arbre selon la formule suivante.
\[c_{outlying} = length(T_{outliers} )/length(T) \].

\smallskip

\textbf{Le Local Outlier Factor(LOF):}
\smallskip
Pour ce critère, on considère un outlier selon son voisinage local\cite{breunig2000lof}.
Le LRD(Local Reachability Density) de chaque point est comparé avec le LRD de ses voisins. Puis on calcule le ratio de la moyenne des LRD des voisins du point sur le LRD du point lui-même. Si le Local Outlier Factor est supérieur à 1 alors le point est un outlier.
Cette mesure est très utile pour détecter des outliers dans les clusters extrêmement denses. Néanmoins cette valeur étant un ratio et non un seuil, elle est parfois compliquée à interpréter en fonction de la problématique de recherche.


\subsubsection{Critères de formes}

Les informations sur la forme de la projection sont également très importantes.\cite{wilkinson2005graph-MST}
La forme est souvent définie par le critère \textit{skinny}. Ce critère représente grossièrement la
finesse de la courbe. Celui-ci est défini en calculant le ratio aire/périmètre d’une projection
(avec normalisation) \[ C_{skinny} = 1 - \sqrt{4\pi area(A)}/perimeter(A) \]

Dans le cas où le chemin le plus court d’un Minimum Spanning Tree est quasiment aussi
long que la somme des arêtes de l’arbre d’origine, la courbe peut être qualifiée de \textit{stringy} \[C_{stringy} = diameter(T)/length(T) \]

\subsubsection{Critère de densité}
Dans une configuration éparpillée (scattered) il y a également le critère de densité qui
importe. C’est la distribution des arêtes du Minimum Spanning Tree qui va donner des
informations sur la densité relative de points.
Le calcul de cette densité se base sur la mesure des quantiles de la longueur des arêtes : 
\[c_{skew} = (q_{90}-q_{50})/(q_{90}-q_{10})\]
Ainsi, si la dimension d’un Minimum Spanning Tree est extrêmement asymétrique, les
clusters y seront mal représentés. Dans ce cas, elle est qualifiée de \textit{clumpy}. \cite{wilkinson2005graph-MST}


\subsubsection{Score de Projection \textit{(seulement pour l'ACP)}}
Les informations d’une projection par ACP sont mesurées en comparant la variance totale du jeu de données et celle qui a été retenue après la réduction de dimension. Ce qui la rend très dépendante du nombre de dimensions du jeu de données de base.\newline
Ainsi, contrairement aux petits jeux de données, il est quasiment impossible que les trois composantes principales d’un grand jeu de données retiennent 100 pourcents(ou quasiment 100 pourcents) de la variance. Et ce, même si le jeu de données est composé de variables non aléatoires avec des structures très facilement interprétables.
\smallskip
Le but de cette méthode est de quantifier l’informativité de la projection non pas par la variance finale, mais par l'excès de variance de ce qui est attendu après réduction d’un dataset aléatoire.
Pour calculer le score de projection: on calcule la variance totale qui est retenue par les 3 principaux composants. Ensuite, on estime la valeur de ces mêmes entités, mais pour un jeu de variables complètement aléatoire.\newline
Enfin, on calcule le score de projection en faisant différence entre la racine carrée de la quantité observée et de la racine carrée de la valeur attendue (celle du random dataset).  Ainsi, si le résultat est grand(s’éloigne positivement de zéro) cela veut dire qu’il y a plus d’informations (relatives au calcul de la variance) pour le vrai jeu de donné que pour celui du jeu de données aléatoire.
Par conséquent, la projection est plus susceptible de proposer des structures fidèles et intéressantes, qui ne sont pas dues au hasard\cite{fontes2011ProjectionScore}.




\subsection{Conclusion de la partie} 
Ces mesures de qualité sont donc utiles pour les personnes non spécialistes, ce qui leur permet d’appréhender au mieux la visualisation obtenue après projection.
Elles peuvent également être utilisées de façon automatique dans des algorithmes qui permettent de trier et de déterminer si la projection qui va être affichée est fidèle au jeu de données\cite{bertini2011quality-AutomatisationAlgo}. 
\newline
Comme nous l’avons brièvement abordé dans l'introduction, les facteurs numériques à eux seuls ne suffisent pas à l’interprétation d’une projection : il faut rajouter le facteur humain à l’équation.
Malgré l’utilité de toutes ces mesures, le jugement humain reste toujours le plus important\cite{AndradaTatu2010visual}. De plus, c'est également l’être humain qui a pour rôle d’interpréter la projection.  C’est pour cela qu’il existe des évaluations à faire passer aux humains, qui servent à mesurer l’impact des techniques de projection, la qualité des graphiques et leur compréhension par l’utilisateur. Par exemple ,nous pouvons tester directement les utilisateurs avec plusieurs types de tâches telles que le “data outlier validation”, le “clustering validation”, le “cluster énumération”, et le “class outliers validation” \cite{HeulotAnEvaluation}. 
Ces tests consistent en la détection des structures et des données aberrantes dans les projections.
Ainsi si une projection a une bonne qualité (suivant les critères numériques) et permet aux utilisateurs de discriminer rapidement et correctement les structures,elle tend alors vers ce que l’on peut considérer comme étant une “bonne projection”.
 





