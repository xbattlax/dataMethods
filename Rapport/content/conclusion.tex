\sectionnn{Conclusion}
Comme ça a été mentionné dans l’état de l’art la visualisation des grands jeux de donnée souffre de cette malédiction de la dimensionalité. Le problème des projections dans ce cas précis n’est pas celui de projeter les données, mais celui de les projeter fidèlement. 
C’est-à-dire, la difficulté pour la méthode à respecter le rapport des distances des points entre le jeu de donné original (à n-dimensions) et la projection finale (qui réduit ce dernier à deux ou 3 dimensions). 
Plus le nombre de dimensions augmente, plus il devient compliqué de respecter les distances après réduction. 
\newline
Le choix d’une méthode de projection par rapport à une autre dépend d'autant plus de la sémantique et de la structure des données. Ce choix dépendra aussi de ce que l’on souhaite observer : voulons-nous mettre en valeur les classes ? Voulons-nous détecter des valeurs aberrantes? 
En fonction de cela, le choix de la méthode et de son paramétrage peut grandement différer.
\smallskip
Une fois le jeu de données projeté, il faut s’assurer de la qualité de cette projection.
Pour cela nous disposons de nombreux critères qui peuvent donner un indice sur le clustering, outlying et la densité de la projection. Certains critères sont même propres à certaines méthodes(comme le projection score pour l'ACP).
Encore une fois, en fonction de ce que nous voulons observer certains critères seront plus utiles que d'autres. De plus, ces critères ne font pas tout : d’une certaine façon, une projection se doit d’être à la fois la plus compréhensible par l’Homme et la plus fidèle possible au jeu de données qu’elle représente.


\medskip
C'est dans ce but, que dans la partie réalisation de cette UE, nous souhaitons mettre en place une évaluation des différentes méthodes de projections citées.
Pour faire cela, nous envisageons de procéder de la façon suivante: \newline
Au vu de nos nombreuses lectures et  des résultats sur notre jeu de données tests (Globe), nous avons déduit que la méthode ClassNeRV est la plus performante et donne les résultats les plus satisfaisants. 
Par conséquent, nous souhaitons effectuer un étalonnage des différentes autres méthodes de projection, en l'utilisant en tant que référentiel. \newline
Notre idée est donc la suivante : lorsqu'un jeu de donnée sera projeté avec une autre méthode de projection, 
le résultat obtenu sera comparé à la projection de ce même jeu de donnée obtenue via ClassNerV.
Puis, en fonction des divergences entre ces deux jeux de données projetés, certains biais seront mesurés et affichés.
De plus dans l'objectif d'être le plus précis possible, nous envisageons également de mesurer les différents critères de la projection(clustering, outlying, forme...) et de croiser les résultats obtenus à ceux de la comparaison des deux projections.
Nous pensons aussi qu'il serait judicieux de mettre en place un système de "scoring", qui permettrait de rendre plus intuitive l'appréhension des résultats relatifs à la qualité de la visualisation. 
\newline 
Le but de cette démarche est de proposer un outil capable de comparer sa méthode de projection à d'autres via un tableau de scoring pour se rendre compte de la pertinence et de la fidélité des diverses méthode de projection.

\medskip

